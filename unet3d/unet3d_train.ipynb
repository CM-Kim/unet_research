{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38864bittorchx86condad5999c8bd9c4485a99dbef96feddd77f",
   "display_name": "Python 3.8.8 64-bit ('torch_x86': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchio as tio\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from layer.component import EncoderBlock, DecoderBlock\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nibabel as nib\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from torchio.transforms import (\n",
    "    RandomFlip,\n",
    "    RandomAffine,\n",
    "    RandomElasticDeformation, \n",
    "    RandomNoise,\n",
    "    RandomMotion,\n",
    "    RandomBiasField,\n",
    "    RescaleIntensity,\n",
    "    Resample,\n",
    "    ToCanonical,\n",
    "    ZNormalization,\n",
    "    CropOrPad,\n",
    "    HistogramStandardization,\n",
    "    OneOf,\n",
    "    Compose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = nib.load(r'data\\0160_20180601_190903_T2FLAIR_to_MAG.nii.gz')\n",
    "# train_mask = nib.load(r'data\\0160_20180601_190903_T2FLAIR_to_MAG_ROI.nii.gz')\n",
    "\n",
    "# # header = proxy.header\n",
    "# # print(header)\n",
    "# # print(header['dim'])\n",
    "# image_dataset = train_data.get_fdata()[:,:,10:42]\n",
    "# mask_dataset = train_mask.get_fdata()[:,:,10:42]\n",
    "\n",
    "# train_data.shape\n",
    "print(type(tio.datasets.ICBM2009CNonlinearSymmetric()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset_load(base_path, mask_path):\n",
    "\n",
    "    dataset_dir = Path(base_path)\n",
    "    maskset_dir = Path(mask_path)\n",
    "    \n",
    "    image_paths = sorted(dataset_dir.glob('*.nii.gz'))\n",
    "    label_paths = sorted(maskset_dir.glob('*.nii.gz'))\n",
    "    print(len(image_paths), len(label_paths))\n",
    "\n",
    "    assert len(image_paths) == len(label_paths)\n",
    "\n",
    "    T2F = 't2f'\n",
    "    LABEL = 'label'\n",
    "    subjects = []\n",
    "\n",
    "    training_transform = tio.Compose([\n",
    "    tio.ToCanonical(),\n",
    "    # tio.CropOrPad((256,128,32)),\n",
    "    # tio.Resample(2),\n",
    "    # tio.RandomMotion(p=0.2),\n",
    "    # tio.RandomBiasField(p=0.3),\n",
    "    # tio.RandomNoise(p=0.5),\n",
    "    # tio.RandomFlip(axes=(0,)),\n",
    "    # tio.RandomAffine(),\n",
    "    # ZNormalization(),\n",
    "    ])\n",
    "\n",
    "    for (image_path, label_path) in zip(image_paths, label_paths):\n",
    "        subject = tio.Subject(\n",
    "            T2F = tio.ScalarImage(image_path),\n",
    "            LABEL = tio.LabelMap(label_path),\n",
    "        )\n",
    "        subjects.append(subject)\n",
    "    dataset = tio.SubjectsDataset(subjects, transform=training_transform)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset_load(\n",
    "    base_path=r'data/image',\n",
    "    mask_path=r'data/mask'\n",
    ")\n",
    "\n",
    "training_set._subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_size = 1\n",
    "training_loader = torch.utils.data.DataLoader(dataset = training_set, batch_size = training_batch_size, shuffle = True,\n",
    "                                              num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS_DIMENSION = 1\n",
    "SPATIAL_DIMENSIONS = 2,3,4\n",
    "\n",
    "class UnetModel(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, model_depth=4, final_activation=\"sigmoid\"):\n",
    "        super(UnetModel, self).__init__()\n",
    "        self.encoder = EncoderBlock(in_channels=in_channels, model_depth=model_depth)\n",
    "        self.decoder = DecoderBlock(out_channels=out_channels, model_depth=model_depth)\n",
    "        if final_activation == \"sigmoid\":\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "        else:\n",
    "            self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, downsampling_features = self.encoder(x)\n",
    "        x = self.decoder(x, downsampling_features)\n",
    "        x = self.sigmoid(x)\n",
    "        # print(\"Final output shape: \", x.shape)\n",
    "        return x\n",
    "        \n",
    "def get_model_and_optimizer(device):\n",
    "    model = UnetModel(in_channels=1, out_channels=1).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(Function):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input, target, save=True):\n",
    "        if save:\n",
    "            self.save_for_backward(input, target)\n",
    "        eps = 0.000001\n",
    "        _, result_ = input.max(1)\n",
    "        result_ = torch.squeeze(result_)\n",
    "        if input.is_cuda:\n",
    "            result = torch.cuda.FloatTensor(result_.size())\n",
    "            self.target_ = torch.cuda.FloatTensor(target.size())\n",
    "        else:\n",
    "            result = torch.FloatTensor(result_.size())\n",
    "            self.target_ = torch.FloatTensor(target.size())\n",
    "        result.copy_(result_)\n",
    "        self.target_.copy_(target)\n",
    "        target = self.target_\n",
    "#       print(input)\n",
    "        intersect = torch.dot(result, target)\n",
    "        # binary values so sum the same as sum of squares\n",
    "        result_sum = torch.sum(result)\n",
    "        target_sum = torch.sum(target)\n",
    "        union = result_sum + target_sum + (2*eps)\n",
    "\n",
    "        # the target volume can be empty - so we still want to\n",
    "        # end up with a score of 1 if the result is 0/0\n",
    "        IoU = intersect / union\n",
    "        print('union: {:.3f}\\t intersect: {:.6f}\\t target_sum: {:.0f} IoU: result_sum: {:.0f} IoU {:.7f}'.format(\n",
    "            union, intersect, target_sum, result_sum, 2*IoU))\n",
    "        out = torch.FloatTensor(1).fill_(2*IoU)\n",
    "        self.intersect, self.union = intersect, union\n",
    "        return out\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        input, _ = self.saved_tensors\n",
    "        intersect, union = self.intersect, self.union\n",
    "        target = self.target_\n",
    "        gt = torch.div(target, union)\n",
    "        IoU2 = intersect/(union*union)\n",
    "        pred = torch.mul(input[:, 1], IoU2)\n",
    "        dDice = torch.add(torch.mul(gt, 2), torch.mul(pred, -4))\n",
    "        grad_input = torch.cat((torch.mul(dDice, -grad_output[0]),\n",
    "                                torch.mul(dDice, grad_output[0])), 0)\n",
    "        return grad_input , None\n",
    "\n",
    "def dice_loss(input, target):\n",
    "    return DiceLoss()(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, verbose=True)\n",
    "\n",
    "model, optimizer = get_model_and_optimizer(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for subjects_batch in training_loader:\n",
    "        inputs = subjects_batch['T2F'][tio.DATA].to(device)\n",
    "        target = subjects_batch['LABEL'][tio.DATA].to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = dice_loss(inputs,target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"epoch : {epoch} | loss : {loss.item()} iou : {iou}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1000):\n",
    "#     for batch_idx, samples in enumerate(train):\n",
    "#         # 순전파 단계 : 모델에서 x에 대한 예측 값 y_pred를 계산합니다.\n",
    "\n",
    "#         x_batch, y_batch = samples\n",
    "\n",
    "#         y_pred = model(x_batch)\n",
    "#         y_pred = y_pred.cpu()\n",
    "\n",
    "#         loss = loss_function(y_pred,y_batch)\n",
    "#         scheduler.step(loss)\n",
    "\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # 역전파 단계\n",
    "#         loss.backward()\n",
    "\n",
    "#         # optimizer의 step 함수를 호출 하면 매개 변수가 갱신됨\n",
    "#         optimizer.step()\n",
    "\n",
    "#         print(f\"epoch {epoch} | batch {batch_idx+1}/{len(dataloader)} | lose : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}