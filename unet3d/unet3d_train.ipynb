{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "62b36ad15c9cb3cf8ba13ba90ae4a5eecbbb07a7ead0fedcbc156bc940ebce47"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchio as tio\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from layer.component import EncoderBlock, DecoderBlock\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nibabel as nib\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from torchio.transforms import (\n",
    "    RandomFlip,\n",
    "    RandomAffine,\n",
    "    RandomElasticDeformation, \n",
    "    RandomNoise,\n",
    "    RandomMotion,\n",
    "    RandomBiasField,\n",
    "    RescaleIntensity,\n",
    "    Resample,\n",
    "    ToCanonical,\n",
    "    ZNormalization,\n",
    "    CropOrPad,\n",
    "    HistogramStandardization,\n",
    "    OneOf,\n",
    "    Compose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torchio.datasets.mni.icbm.ICBM2009CNonlinearSymmetric'>\n"
     ]
    }
   ],
   "source": [
    "# train_data = nib.load(r'data\\0160_20180601_190903_T2FLAIR_to_MAG.nii.gz')\n",
    "# train_mask = nib.load(r'data\\0160_20180601_190903_T2FLAIR_to_MAG_ROI.nii.gz')\n",
    "\n",
    "# # header = proxy.header\n",
    "# # print(header)\n",
    "# # print(header['dim'])\n",
    "# image_dataset = train_data.get_fdata()[:,:,10:42]\n",
    "# mask_dataset = train_mask.get_fdata()[:,:,10:42]\n",
    "\n",
    "# train_data.shape\n",
    "print(type(tio.datasets.ICBM2009CNonlinearSymmetric()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset_load(base_path, mask_path):\n",
    "\n",
    "    dataset_dir = Path(base_path)\n",
    "    maskset_dir = Path(mask_path)\n",
    "    \n",
    "    image_paths = sorted(dataset_dir.glob('*.nii.gz'))\n",
    "    label_paths = sorted(maskset_dir.glob('*.nii.gz'))\n",
    "    print(len(image_paths), len(label_paths))\n",
    "\n",
    "    assert len(image_paths) == len(label_paths)\n",
    "\n",
    "    T2F = 't2f'\n",
    "    LABEL = 'label'\n",
    "    subjects = []\n",
    "\n",
    "    training_transform = tio.Compose([\n",
    "    tio.ToCanonical(),\n",
    "    tio.CropOrPad((128,128,32)),\n",
    "    # tio.Resample(2),\n",
    "    # tio.RandomMotion(p=0.2),\n",
    "    # tio.RandomBiasField(p=0.3),\n",
    "    # tio.RandomNoise(p=0.5),\n",
    "    # tio.RandomFlip(axes=(0,)),\n",
    "    # tio.RandomAffine(),\n",
    "    # ZNormalization(),\n",
    "    ])\n",
    "\n",
    "    for (image_path, label_path) in zip(image_paths, label_paths):\n",
    "        subject = tio.Subject(\n",
    "            T2F = tio.ScalarImage(image_path),\n",
    "            LABEL = tio.LabelMap(label_path),\n",
    "        )\n",
    "        subjects.append(subject)\n",
    "    dataset = tio.SubjectsDataset(subjects, transform=training_transform)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3 3\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Subject(Keys: ('T2F', 'LABEL'); images: 2),\n",
       " Subject(Keys: ('T2F', 'LABEL'); images: 2),\n",
       " Subject(Keys: ('T2F', 'LABEL'); images: 2)]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "training_set = Dataset_load(\n",
    "    base_path=r'data\\image',\n",
    "    mask_path=r'data\\mask'\n",
    ")\n",
    "\n",
    "training_set._subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_size = 1\n",
    "training_loader = torch.utils.data.DataLoader(dataset = training_set, batch_size = training_batch_size, shuffle = True,\n",
    "                                              num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS_DIMENSION = 1\n",
    "SPATIAL_DIMENSIONS = 2,3,4\n",
    "\n",
    "class UnetModel(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, model_depth=4, final_activation=\"sigmoid\"):\n",
    "        super(UnetModel, self).__init__()\n",
    "        self.encoder = EncoderBlock(in_channels=in_channels, model_depth=model_depth)\n",
    "        self.decoder = DecoderBlock(out_channels=out_channels, model_depth=model_depth)\n",
    "        if final_activation == \"sigmoid\":\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "        else:\n",
    "            self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, downsampling_features = self.encoder(x)\n",
    "        x = self.decoder(x, downsampling_features)\n",
    "        x = self.sigmoid(x)\n",
    "        # print(\"Final output shape: \", x.shape)\n",
    "        return x\n",
    "\n",
    "def prepare_batch(batch, device):\n",
    "  inputs = batch['T2F'][tio.DATA].to(device)\n",
    "  foreground = batch['LABEL'][tio.DATA].type(torch.float32).to(device)\n",
    "  background = 1 - foreground\n",
    "  targets = torch.cat((background, foreground), dim = CHANNELS_DIMENSION)\n",
    "  return inputs, targets\n",
    "\n",
    "def get_dice_score(output, target, epsilon = 1e-9):\n",
    "  p0 = output\n",
    "  g0 = target\n",
    "  p1 = 1 - p0\n",
    "  g1 = 1 - g0\n",
    "  tp = (p0 * g0).sum(dim = SPATIAL_DIMENSIONS)\n",
    "  fp = (p0 * g1).sum(dim = SPATIAL_DIMENSIONS)\n",
    "  fn = (p1 * g0).sum(dim = SPATIAL_DIMENSIONS)\n",
    "  num = 2 * tp\n",
    "  denom = 2 * tp + fp + fn + epsilon\n",
    "  dice_score = num / denom\n",
    "\n",
    "  return dice_score\n",
    "\n",
    "def get_dice_loss(output, target):\n",
    "  return 1 - get_dice_score(output, target)\n",
    "\n",
    "def forward(model, inputs):\n",
    "  with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "    logits = model(inputs)\n",
    "  return logits\n",
    "def get_model_and_optimizer(device):\n",
    "    model = UnetModel(in_channels=1, out_channels=1).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    r\"\"\"Criterion that computes Sørensen-Dice Coefficient loss.\n",
    "\n",
    "    According to [1], we compute the Sørensen-Dice Coefficient as follows:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\text{Dice}(x, class) = \\frac{2 |X| \\cap |Y|}{|X| + |Y|}\n",
    "\n",
    "    where:\n",
    "       - :math:`X` expects to be the scores of each class.\n",
    "       - :math:`Y` expects to be the one-hot tensor with the class labels.\n",
    "\n",
    "    the loss, is finally computed as:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\text{loss}(x, class) = 1 - \\text{Dice}(x, class)\n",
    "\n",
    "    [1] https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C, H, W)` where C = number of classes.\n",
    "        - Target: :math:`(N, H, W)` where each value is\n",
    "          :math:`0 ≤ targets[i] ≤ C−1`.\n",
    "\n",
    "    Examples:\n",
    "        >>> N = 5  # num_classes\n",
    "        >>> loss = tgm.losses.DiceLoss()\n",
    "        >>> input = torch.randn(1, N, 3, 5, requires_grad=True)\n",
    "        >>> target = torch.empty(1, 3, 5, dtype=torch.long).random_(N)\n",
    "        >>> output = loss(input, target)\n",
    "        >>> output.backward()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.eps: float = 1e-6\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input: torch.Tensor,\n",
    "            target: torch.Tensor) -> torch.Tensor:\n",
    "        if not torch.is_tensor(input):\n",
    "            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                            .format(type(input)))\n",
    "        if not len(input.shape) == 5:\n",
    "            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n",
    "                             .format(input.shape))\n",
    "        if not input.shape[-2:] == target.shape[-2:]:\n",
    "            raise ValueError(\"input and target shapes must be the same. Got: {}\"\n",
    "                             .format(input.shape, input.shape))\n",
    "        if not input.device == target.device:\n",
    "            raise ValueError(\n",
    "                \"input and target must be in the same device. Got: {}\" .format(\n",
    "                    input.device, target.device))\n",
    "        # compute softmax over the classes axis\n",
    "        input_soft = F.softmax(input, dim=1)\n",
    "\n",
    "        # create the labels one hot tensor\n",
    "        target_one_hot = one_hot(target, num_classes=input.shape[1],\n",
    "                                 device=input.device, dtype=input.dtype)\n",
    "\n",
    "        # compute the actual dice score\n",
    "        dims = (1, 2, 3)\n",
    "        intersection = torch.sum(input_soft * target_one_hot, dims)\n",
    "        cardinality = torch.sum(input_soft + target_one_hot, dims)\n",
    "\n",
    "        dice_score = 2. * intersection / (cardinality + self.eps)\n",
    "        return torch.mean(1. - dice_score)\n",
    "\n",
    "def dice_loss(\n",
    "        input: torch.Tensor,\n",
    "        target: torch.Tensor) -> torch.Tensor:\n",
    "    r\"\"\"Function that computes Sørensen-Dice Coefficient loss.\n",
    "\n",
    "    See :class:`~torchgeometry.losses.DiceLoss` for details.\n",
    "    \"\"\"\n",
    "    return DiceLoss()(input, target)\n",
    "    \n",
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    \n",
    "    intersection = torch.bitwise_and(outputs, labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = torch.bitwise_or(outputs,labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    \n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean() if you are interested in average across the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Invalid input shape, we expect BxNxHxW. Got: torch.Size([3, 1, 128, 128, 32])",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b5028a9beea9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d074276960a4>\u001b[0m in \u001b[0;36mdice_loss\u001b[1;34m(input, target)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mSee\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mtorchgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDiceLoss\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \"\"\"\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mDiceLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0miou_pytorch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d074276960a4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m     46\u001b[0m                             .format(type(input)))\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n\u001b[0m\u001b[0;32m     49\u001b[0m                              .format(input.shape))\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid input shape, we expect BxNxHxW. Got: torch.Size([3, 1, 128, 128, 32])"
     ]
    }
   ],
   "source": [
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, verbose=True)\n",
    "\n",
    "model, optimizer = get_model_and_optimizer(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for subjects_batch in training_loader:\n",
    "        inputs = subjects_batch['T2F'][tio.DATA].to(device)\n",
    "        target = subjects_batch['LABEL'][tio.DATA].to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = dice_loss(inputs,target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"epoch : {epoch} | loss : {loss.item()} iou : {iou}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1000):\n",
    "#     for batch_idx, samples in enumerate(train):\n",
    "#         # 순전파 단계 : 모델에서 x에 대한 예측 값 y_pred를 계산합니다.\n",
    "\n",
    "#         x_batch, y_batch = samples\n",
    "\n",
    "#         y_pred = model(x_batch)\n",
    "#         y_pred = y_pred.cpu()\n",
    "\n",
    "#         loss = loss_function(y_pred,y_batch)\n",
    "#         scheduler.step(loss)\n",
    "\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # 역전파 단계\n",
    "#         loss.backward()\n",
    "\n",
    "#         # optimizer의 step 함수를 호출 하면 매개 변수가 갱신됨\n",
    "#         optimizer.step()\n",
    "\n",
    "#         print(f\"epoch {epoch} | batch {batch_idx+1}/{len(dataloader)} | lose : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}